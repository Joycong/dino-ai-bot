# 📌 experiment/good-memory 브랜치 업데이트 비교 요약

이 문서는 `기존 좋은 메모리 버전`과 `업데이트 강화 버전`의 주요 차이점을 요약합니다.

---

## 🔄 업데이트된 핵심 변경 사항

### 1. 🎯 좋은 메모리 저장 방식 개선

- **기존**:
  - 장애물 개수 조건(`threshold`)을 넘기면, 매 스텝마다 `good_memory`에 저장

- **업데이트 후**:
  - 장애물 통과(`reward == 1`) 직후에만 `good_memory` 저장
  - 의미 없는 경험(예: 점프 실패 후 대기 등)을 줄여, **좋은 경험 위주로 메모리 최적화**

> ✅ 좋은 메모리 품질을 높여 학습 효율 상승

---

### 2. 📈 좋은 메모리 우선 비율 계산 방식 개선

- **기존**:
  - 고정 비율 (예: `good_ratio = 0.8`) 사용하여 batch에서 좋은 메모리를 뽑음

- **업데이트 후**:
  - 현재 good memory 수를 기반으로 **동적 비율 계산**:

    ```
    good_ratio = min(0.9, len(good_memory) / (len(memory) + 1))
    ```

> ✅ 좋은 메모리 비율을 데이터 양에 맞춰 조절 → 균형 잡힌 학습

---

### 3. 🚀 초기 탐험률 설정 변경

- **기존**:
  - 초기 ε = 1.0

- **업데이트 후**:
  - 초기 ε = 0.9 (`INITIAL_EPSILON = 0.9`)

> ✅ 너무 무작위적인 초기 행동을 줄이고, 학습 초기 안정성 확보

---

### 4. 🔽 탐험률 감소 로직 강화

- **기존**:
  - `EPSILON_DECAY = 0.900`
  - 장애물 기록 갱신 시 감소율(`decay_multiplier`) = `1.0 + diff * 0.1`

- **업데이트 후**:
  - `EPSILON_DECAY = 0.98`
  - 장애물 기록 갱신 시 감소율 강화:

    ```
    decay_multiplier = 1.0 + diff * 0.2
    ```

> ✅ 장애물 통과 성과가 클수록 더 빠르게 탐험률 감소 → 더 빨리 exploitation(최적화) 전환

---

### 5. 📊 옵티마이저(Optimizer) 학습률 변경

- **기존**:
  - Adam optimizer 학습률 = 0.001

- **업데이트 후**:
  - Adam optimizer 학습률 = 0.005

> ✅ 초기 학습 속도를 높여 빠른 수렴 기대

---

### 6. 🧹 메모리 저장 정책 최적화

- **기존**:
  - 모든 스텝을 메모리에 저장

- **업데이트 후**:
  - 장애물 통과(`reward == 1`) 직후만 메모리에 저장

> ✅ 메모리 질 향상 및 중요 경험 중심 학습

---

### 7. 🗂 기타 소소한 개선

- 초기 설정 시 경고 제거 (`warnings.filterwarnings` 사용 삭제됨)
- 파일명 정리, 출력 메세지 일부 개선
- 학습 완료 후 출력 메세지 변경 (`"학습 완료!"` → `"🎉 학습 완료!"`)

---

## 📁 저장 구조 변화 없음

| 항목 | 경로 | 설명 |
|------|------|------|
| 모델 저장 | `models/dqn_model_ep{N}.pth` | PyTorch 모델 저장 |
| 메모리 저장 | `memory/replay_ep{N}.pkl` | Replay Memory 저장 |
| 로그 파일 | `logs/training_log.csv` | 에피소드별 보상 및 ε 기록 |

---

## ✨ 이번 업데이트 목적

- 의미 있는 경험 중심 학습 강화
- 빠른 학습 초기화 및 안정성 확보
- 성과 기반 동적 탐험률 제어 강화
- 좋은 메모리 품질 최적화

---
